{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b370576-e331-4079-ad8e-e692891f5ce6",
   "metadata": {},
   "source": [
    "# # Nearest Neighbor Search using NNCLR\n",
    "\n",
    "**Author:** [Lennart Seeger], [Rishit Dagli]<br>\n",
    "**Date created:** 2021/09/13<br>\n",
    "**Last modified:** 2023/03/24<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced7df0b-d683-4f56-b461-cb5c9b9b6f50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "from tensorflow.keras import models, layers, Input\n",
    "from keras.applications.resnet import ResNet50\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "\n",
    "sys.path.insert(1, '../src')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from models.nnclr import NNCLR, get_augmenter, get_encoder\n",
    "from data.datasets import get_mlrsnet, get_denmark\n",
    "from model_utility.learning_rate_scheduler import WarmUpCosine\n",
    "from supportive.evaluate import evaluate_extractor\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6d8a94-021f-4c4f-a754-e8466364f59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset hyperparameters\n",
    "image_size = 64\n",
    "image_channels = 3\n",
    "batch_size=512\n",
    "x_train=np.load(\"../data/avg_std30.npy\")\n",
    "steps_per_epoch = len(x_train)//batch_size\n",
    "\n",
    "# optimizer\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "\n",
    "# Algorithm hyperparameters\n",
    "num_epochs = 50\n",
    "width = 2048\n",
    "temperature = 0.1\n",
    "queue_size=1024 # needs to be higher than batch_size\n",
    "input_shape = (image_size, image_size, 3)\n",
    "\n",
    "# augmentation definitions\n",
    "contrastive_augmentation = {\n",
    "    \"brightness\": 0.5,\n",
    "    \"name\": \"contrastive_augmenter\",\n",
    "    \"scale\": (0.2, 1.0),\n",
    "}\n",
    "classification_augmentation = {\n",
    "    \"brightness\": 0.2,\n",
    "    \"name\": \"classification_augmenter\",\n",
    "    \"scale\": (0.5, 1.0),\n",
    "}\n",
    "x_test, y_test = get_denmark(image_size=image_size)\n",
    "\n",
    "\"\"\"Encoder implementation\"\"\"\n",
    "baseModel = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(image_size, image_size, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d52624-4e5a-4c1a-9ac3-7a5ea9d6f2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset handling\n",
    "y_train=np.array([-1]*len(x_train))\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0421be-e07a-46ee-a22e-d73df57daa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_steps = steps_per_epoch * num_epochs\n",
    "warmup_epoch_percentage = 0.15\n",
    "warmup_steps = int(total_steps * warmup_epoch_percentage)\n",
    "scheduled_lrs = WarmUpCosine(\n",
    "    learning_rate_base=learning_rate,\n",
    "    total_steps=total_steps,\n",
    "    warmup_learning_rate=0.0,\n",
    "    warmup_steps=warmup_steps,\n",
    ")\n",
    "\n",
    "lrs = [scheduled_lrs(step) for step in range(total_steps)]\n",
    "plt.plot(lrs)\n",
    "plt.xlabel(\"Step\", fontsize=14)\n",
    "plt.ylabel(\"LR\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726bc0a2-a3c3-4be6-9c72-ec79af5c1437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrastive pretraining\n",
    "optimizer=tfa.optimizers.AdamW(learning_rate=scheduled_lrs, weight_decay=weight_decay)\n",
    "\n",
    "pretraining_model = NNCLR(**contrastive_augmentation, temperature=temperature, queue_size=queue_size, image_size=image_size, baseModel=baseModel, width=width)\n",
    "pretraining_model.compile(\n",
    "    contrastive_optimizer=optimizer,\n",
    "    probe_optimizer=tf.keras.optimizers.Adam(),\n",
    "    run_eagerly=True,\n",
    ")\n",
    "pretraining_history = pretraining_model.fit(\n",
    "    train_ds.batch(batch_size, drop_remainder=True).repeat(), epochs=num_epochs, validation_data=None,steps_per_epoch = steps_per_epoch,\n",
    "                    #validation_steps = validation_steps,#, test_dataset#train_dataset, # val_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ddb004-67fa-4d27-b409-63f01df18cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "path=\"../model/nnclr/model\"\n",
    "pretraining_model.encoder.save(path)\n",
    "model_loaded = keras.models.load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1add1c-5418-4bf6-a675-8e49ced7cc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build extractor\n",
    "extractor_model = keras.Sequential(\n",
    "    [\n",
    "        layers.Input((image_size, image_size, 3)),\n",
    "        pretraining_model.classification_augmenter,\n",
    "        model_loaded\n",
    "    ],\n",
    "    name=\"extraction_model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35beef85-9776-4298-ab8f-463fc5527849",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet = ResNet50(weights='imagenet', include_top=False,input_shape=(image_size,image_size,3),pooling=\"avg\")\n",
    "print(x_test.shape, y_test.shape)\n",
    "print(\"extractor_model: \", evaluate_extractor(extractor_model.predict, x_test, y_test, neighbors=10))\n",
    "print(\"model_resnet: \", evaluate_extractor(model_resnet.predict, x_test, y_test, neighbors=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94758b60-7033-4cf1-824f-ef1782912202",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../model/nnclr/results.txt', 'a') as file:\n",
    "    file.write('\\n------------------------------------------')\n",
    "    file.write(\"\\nextractor_model: : \"+str(evaluate_extractor(extractor_model.predict, x_test, y_test, neighbors=10)))\n",
    "    file.write(\"\\nbatch_size: \"+str(batch_size))\n",
    "    file.write(\"\\nnum_epochs: \"+str(num_epochs))\n",
    "    file.write(\"\\nsteps_per_epoch: \"+str(steps_per_epoch))\n",
    "    file.write(\"\\noptimizer: \"+str(optimizer))\n",
    "    file.write(\"\\ntemperature: \"+str(temperature))\n",
    "    file.write(\"\\ncontrastive_augmentation: \"+str(contrastive_augmentation))\n",
    "    file.write(\"\\nclassification_augmentation: \"+str(classification_augmentation))\n",
    "    file.write(\"\\nqueue_size: \"+str(queue_size))\n",
    "    stringlist = []\n",
    "    baseModel.summary(print_fn=lambda x: stringlist.append(x))\n",
    "    short_model_summary = \"\\n\".join(stringlist)\n",
    "    file.write(\"\\n\"+short_model_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
